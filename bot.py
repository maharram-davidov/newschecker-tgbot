import os
import logging
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes, ApplicationBuilder
import google.generativeai as genai
import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from serpapi import GoogleSearch
import json
from datetime import datetime, timedelta
import re
import easyocr
from PIL import Image
import io
import numpy
from config import get_official_search_params, get_news_search_params

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Initialize Gemini
genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
model = genai.GenerativeModel('gemini-2.0-flash')

# Initialize EasyOCR reader
reader = easyocr.Reader(['az', 'en'])

def extract_sources_from_text(text):
    """Extract mentioned sources from the news text using Gemini."""
    try:
        prompt = f"""
        Bu x…ôb…ôr m…ôtni i√ß…ôrisind…ô istinad edil…ôn m…ônb…ôl…ôri tap v…ô √ßƒ±xar.
        M…ônb…ôl…ôr bunlar ola bil…ôr:
        - R…ôsmi saytlar (m…ôs: gov.az, who.int)
        - X…ôb…ôr agentlikl…ôri (m…ôs: Reuters, AP)
        - R…ôsmi ≈ü…ôxsl…ôr (m…ôs: Prezident, Nazir)
        - R…ôsmi s…ôn…ôdl…ôr (m…ôs: q…ôrar, s…ôr…ôncam)
        - R…ôsmi t…ô≈ükilatlar (m…ôs: BMT, DST)
        
        X…ôb…ôr m…ôtni:
        {text}
        
        Z…ôhm…ôt olmasa a≈üaƒüƒ±dakƒ± formatda qaytar:
        - M…ônb…ô adƒ±: [m…ônb…ônin adƒ±]
        - M…ônb…ô n√∂v√º: [r…ôsmi sayt/x…ôb…ôr agentliyi/r…ôsmi ≈ü…ôxs/r…ôsmi s…ôn…ôd/r…ôsmi t…ô≈ükilat]
        - ƒ∞stinad m…ôtni: [x…ôb…ôrd…ô bu m…ônb…ôy…ô nec…ô istinad edilib]
        """
        
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        logger.error(f"Error in extract_sources_from_text: {e}")
        return ""

def verify_mentioned_sources(sources_text, keywords):
    """Verify the mentioned sources using SerpAPI."""
    try:
        # Get current date and date from 7 days ago
        current_date = datetime.now()
        week_ago = current_date - timedelta(days=7)
        date_range = f"after:{week_ago.strftime('%Y-%m-%d')}"
        
        # Extract source names from the sources text
        source_names = re.findall(r'M…ônb…ô adƒ±: (.*?)(?:\n|$)', sources_text)
        
        verification_results = []
        for source in source_names:
            # Search for the source and keywords
            params = {
                "engine": "google",
                "q": f'"{source}" {keywords} {date_range}',
                "api_key": os.getenv('SERPAPI_API_KEY'),
                "num": 3
            }
            
            search = GoogleSearch(params)
            results = search.get_dict()
            
            if "organic_results" in results:
                verification_results.append({
                    "source": source,
                    "results": results["organic_results"]
                })
        
        return verification_results
    except Exception as e:
        logger.error(f"Error in verify_mentioned_sources: {e}")
        return []

def search_news_sources(news_content):
    """Search for the news content in both official and general news sources using SerpAPI."""
    try:
        # Extract key information from the news content using Gemini
        prompt = f"""
        Bu x…ôb…ôr m…ôtnind…ôn …ôsas m…ôlumatlarƒ± √ßƒ±xar v…ô axtarƒ±≈ü √º√ß√ºn …ôn vacib 3-4 a√ßar s√∂z√º tap.
        Yalnƒ±z a√ßar s√∂zl…ôri qaytar, ba≈üqa he√ß n…ô yazma.
        
        X…ôb…ôr m…ôtni:
        {news_content}
        """
        
        response = model.generate_content(prompt)
        keywords = response.text.strip()
        
        # Get current date and date from 7 days ago
        current_date = datetime.now()
        week_ago = current_date - timedelta(days=7)
        date_range = f"after:{week_ago.strftime('%Y-%m-%d')}"
        
        # Get search parameters from config
        official_params = get_official_search_params(keywords, date_range, os.getenv('SERPAPI_API_KEY'))
        news_params = get_news_search_params(keywords, date_range, os.getenv('SERPAPI_API_KEY'))
        
        official_search = GoogleSearch(official_params)
        news_search = GoogleSearch(news_params)
        
        official_results = official_search.get_dict()
        news_results = news_search.get_dict()
        
        return {
            "official_sources": official_results.get("organic_results", []),
            "news_sources": news_results.get("organic_results", []),
            "keywords": keywords
        }
        
    except Exception as e:
        logger.error(f"Error in search_news_sources: {e}")
        return {"official_sources": [], "news_sources": [], "keywords": ""}

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Send a message when the command /start is issued."""
    welcome_message = (
        "Salam! M…ôn x…ôb…ôr doƒüruluq analiz botuyam. üëã\n\n"
        "M…ôn…ô bir x…ôb…ôr linki v…ô ya x…ôb…ôr m…ôtni g√∂nd…ôr…ô bil…ôrsiniz. "
        "M…ôn d…ô x…ôb…ôrin doƒüruluƒüunu analiz edib siz…ô m…ôlumat ver…ôc…ôy…ôm.\n\n"
        "ƒ∞stifad…ô qaydasƒ±:\n"
        "1. Bir x…ôb…ôr linki g√∂nd…ôrin\n"
        "2. V…ô ya x…ôb…ôr m…ôtni birba≈üa yazƒ±n\n"
        "3. M…ôn siz…ô x…ôb…ôrin doƒüruluƒüu haqqƒ±nda …ôtraflƒ± bir analiz t…ôqdim ed…ôc…ôy…ôm."
    )
    await update.message.reply_text(welcome_message)

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Send a message when the command /help is issued."""
    help_text = (
        "Bot ƒ∞stifad…ô T…ôlimatƒ±:\n\n"
        "1. Bir x…ôb…ôr linki g√∂nd…ôrin v…ô ya x…ôb…ôr m…ôtni yazƒ±n\n"
        "2. Bot avtomatik olaraq x…ôb…ôri analiz ed…ôc…ôk\n"
        "3. Siz…ô x…ôb…ôrin doƒüruluƒüu haqqƒ±nda …ôtraflƒ± bir hesabat t…ôqdim olunacaq\n\n"
        "ƒ∞stifad…ô n√ºmun…ôsi:\n"
        "- Bir x…ôb…ôr linki yapƒ±≈üdƒ±rƒ±n\n"
        "- V…ô ya 'Az…ôrbaycanda yeni bir texnologiya ≈üirk…ôti yaradƒ±ldƒ±' kimi bir x…ôb…ôr m…ôtni yazƒ±n"
    )
    await update.message.reply_text(help_text)

def extract_text_from_url(url):
    """Extract text content from a URL."""
    try:
        response = requests.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Remove script and style elements
        for script in soup(["script", "style"]):
            script.decompose()
            
        # Get text content
        text = soup.get_text()
        lines = (line.strip() for line in text.splitlines())
        chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
        text = ' '.join(chunk for chunk in chunks if chunk)
        
        return text[:4000]  # Limit text length
    except Exception as e:
        logger.error(f"Error extracting text from URL: {e}")
        return None

async def extract_text_from_image(image_data):
    """Extract text from image using EasyOCR."""
    try:
        # Convert image data to PIL Image
        image = Image.open(io.BytesIO(image_data))
        
        # Extract text using EasyOCR
        results = reader.readtext(numpy.array(image))
        
        # Combine all detected text
        text = ' '.join([result[1] for result in results])
        
        return text.strip()
    except Exception as e:
        logger.error(f"Error in extract_text_from_image: {e}")
        return None

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle photo messages."""
    try:
        # Get the photo file
        photo = await update.message.photo[-1].get_file()
        
        # Download the photo
        photo_data = await photo.download_as_bytearray()
        
        # Extract text from the photo
        extracted_text = await extract_text_from_image(photo_data)
        
        if not extracted_text:
            await update.message.reply_text("√úzr ist…ôyir…ôm, ≈ü…ôkild…ôn m…ôtn √ßƒ±xara bilm…ôdim. Z…ôhm…ôt olmasa daha yax≈üƒ± keyfiyy…ôtli ≈ü…ôkil g√∂nd…ôrin.")
            return
        
        # Send "analyzing" message
        analyzing_message = await update.message.reply_text("≈û…ôkild…ôn √ßƒ±xarƒ±lan m…ôtn analiz olunur... ü§î")
        
        # Analyze the extracted text
        await analyze_news_content(update, context, extracted_text)
        
        # Delete the "analyzing" message
        await analyzing_message.delete()
        
    except Exception as e:
        logger.error(f"Error in handle_photo: {e}")
        await update.message.reply_text("√úzr ist…ôyir…ôm, ≈ü…ôkil emal edil…ôrk…ôn x…ôta ba≈ü verdi. Z…ôhm…ôt olmasa daha sonra yenid…ôn c…ôhd edin.")

async def analyze_news_content(update: Update, context: ContextTypes.DEFAULT_TYPE, news_content: str):
    """Analyze the news content."""
    try:
        # Extract and verify mentioned sources
        mentioned_sources = extract_sources_from_text(news_content)
        
        # Search in news sources
        search_results = search_news_sources(news_content)
        
        # Verify mentioned sources
        source_verification = verify_mentioned_sources(mentioned_sources, search_results["keywords"])
        
        # Prepare the prompt for Gemini
        prompt = f"""
        Siz bir x…ôb…ôr analiz m√ºt…ôx…ôssisisiniz. X…ôb…ôrl…ôri bit…ôr…ôf v…ô obyektiv ≈ü…ôkild…ô analiz edirsiniz.
        
        A≈üaƒüƒ±dakƒ± x…ôb…ôri analiz et v…ô bu m…ôlumatlarƒ± istifad…ô ed…ôr…ôk …ôtraflƒ± bir analiz hazƒ±rla:
        
        X…ôb…ôr m…ôzmunu:
        {news_content}
        
        X…ôb…ôrd…ô istinad edil…ôn m…ônb…ôl…ôr:
        {mentioned_sources}
        
        M…ônb…ôl…ôrin doƒürulanmasƒ±:
        {json.dumps(source_verification, indent=2, ensure_ascii=False) if source_verification else 'X…ôb…ôrd…ô istinad edil…ôn m…ônb…ôl…ôr tapƒ±lmadƒ± v…ô ya doƒürulanmadƒ±.'}
        
        R…ôsmi m…ônb…ôl…ôrd…ô tapƒ±lan m…ôlumatlar:
        {json.dumps(search_results['official_sources'], indent=2, ensure_ascii=False) if search_results['official_sources'] else 'R…ôsmi m…ônb…ôl…ôrd…ô bu x…ôb…ôrl…ô …ôlaq…ôli m…ôlumat tapƒ±lmadƒ±.'}
        
        Dig…ôr x…ôb…ôr m…ônb…ôl…ôrind…ô tapƒ±lan m…ôlumatlar:
        {json.dumps(search_results['news_sources'], indent=2, ensure_ascii=False) if search_results['news_sources'] else 'Dig…ôr x…ôb…ôr m…ônb…ôl…ôrind…ô bu x…ôb…ôrl…ô …ôlaq…ôli m…ôlumat tapƒ±lmadƒ±.'}
        
        Z…ôhm…ôt olmasa a≈üaƒüƒ±dakƒ± formatda …ôtraflƒ± bir analiz hazƒ±rla:
        
        X…ôb…ôr Analizi:
        
        [Burada x…ôb…ôrin …ôsas m…ôzmununu qƒ±sa ≈ü…ôkild…ô izah edin]
        
        M…ônb…ô Analizi:
        [Burada b√ºt√ºn m…ônb…ôl…ôri (x…ôb…ôrd…ô istinad edil…ôn, r…ôsmi v…ô dig…ôr x…ôb…ôr m…ônb…ôl…ôri) birlikd…ô analiz edin. 
        H…ôr bir m…ônb…ônin etibarlƒ±lƒ±ƒüƒ±nƒ±, doƒüruluƒüunu v…ô x…ôb…ôrl…ô uyƒüunluƒüunu izah edin. 
        M…ônb…ôl…ôr arasƒ±nda uyƒüunluq v…ô ya ziddiyy…ôtl…ôri qeyd edin]
        
        Bit…ôr…ôflik Analizi:
        [X…ôb…ôrin bit…ôr…ôfliyini v…ô m√ºmk√ºn t…ôr…ôfli ifad…ôl…ôri izah edin]
        
        N…ôtic…ô:
        [X…ôb…ôrin √ºmumi qiym…ôtl…ôndirm…ôsini v…ô etibarlƒ±lƒ±q s…ôviyy…ôsini izah edin]
        
        Qeydl…ôr:
        [∆èg…ôr varsa, …ôlav…ô qeydl…ôr v…ô x…ôb…ôrdarlƒ±qlar]
        """

        # Get analysis from Gemini
        response = model.generate_content(prompt)
        analysis = response.text

        # Send the analysis
        await update.message.reply_text(analysis)

    except Exception as e:
        logger.error(f"Error in analyze_news_content: {e}")
        await update.message.reply_text("√úzr ist…ôyir…ôm, bir x…ôta ba≈ü verdi. Z…ôhm…ôt olmasa daha sonra yenid…ôn c…ôhd edin.")

async def analyze_news(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle text messages and analyze news."""
    try:
        # Get the message text
        message_text = update.message.text
        
        # Check if it's a URL
        if message_text.startswith(('http://', 'https://')):
            news_content = extract_text_from_url(message_text)
            if not news_content:
                await update.message.reply_text("√úzr ist…ôyir…ôm, bu linkd…ôn m…ôzmun √ß…ôk…ô bilm…ôdim. Z…ôhm…ôt olmasa ba≈üqa bir link sƒ±nayƒ±n.")
                return
        else:
            news_content = message_text

        # Send "analyzing" message
        analyzing_message = await update.message.reply_text("X…ôb…ôr analiz olunur... ü§î")

        # Analyze the news content
        await analyze_news_content(update, context, news_content)

        # Delete the "analyzing" message
        await analyzing_message.delete()

    except Exception as e:
        logger.error(f"Error in analyze_news: {e}")
        await update.message.reply_text("√úzr ist…ôyir…ôm, bir x…ôta ba≈ü verdi. Z…ôhm…ôt olmasa daha sonra yenid…ôn c…ôhd edin.")

def main():
    """Start the bot."""
    # Create the Application
    application = ApplicationBuilder().token(os.getenv('TELEGRAM_BOT_TOKEN')).build()

    # Add handlers
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, analyze_news))

    # Start the Bot
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main() 